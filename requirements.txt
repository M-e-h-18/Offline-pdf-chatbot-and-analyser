# -----------------------------------------------------------------
# Python Dependencies for Offline PDF Analysis Suite
# -----------------------------------------------------------------
# To install, first set up system dependencies (see below),
# then handle special cases (PyTorch, llama-cpp-python),
# and finally run: pip install -r requirements.txt
# -----------------------------------------------------------------

# Core & Data Handling
numpy>=1.24.0
pandas>=2.0.0
requests>=2.31.0
tqdm>=4.66.0

# ML/AI Frameworks
torch>=2.0.0
scikit-learn>=1.3.0
huggingface-hub>=0.17.0
llama-cpp-python>=0.2.11  # Specify version for clarity
spacy>=3.7.0
# PDF, Table & Image Processing
gradio>=4.0.0
PyMuPDF>=1.23.0
pdf2image>=1.16.0
pytesseract>=0.3.10
camelot-py[cv]>=0.11.0  # For advanced table extraction, includes opencv
Pillow>=10.0.0

# -----------------------------------------------------------------
# System-Level Dependencies (MUST be installed first!)
# -----------------------------------------------------------------
# These are not Python packages and must be installed via your
# system's package manager (apt, brew, etc.).

# For Ubuntu/Debian:
# sudo apt-get update
# sudo apt-get install -y tesseract-ocr tesseract-ocr-eng poppler-utils ghostscript

# For macOS (using Homebrew):
# brew install tesseract poppler ghostscript

# For Windows:
# 1. Tesseract: Download installer from https://github.com/UB-Mannheim/tesseract/wiki
# 2. Poppler: Download binaries from https://blog.alivate.com.au/poppler-windows/
# 3. Ghostscript: Download installer from https://www.ghostscript.com/releases/gsdnld.html
# **IMPORTANT**: Ensure the 'bin' folders for all three are added to your system's PATH.

# -----------------------------------------------------------------
# GPU / Special Installation Instructions
# -----------------------------------------------------------------
# It is strongly recommended to install these in a virtual environment.

# === For NVIDIA GPU Users (CUDA) ===
# 1. Install PyTorch with CUDA support first. Get the correct command for your system from:
#    https://pytorch.org/get-started/locally/
#    Example for CUDA 12.1:
#    pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

# 2. Install llama-cpp-python with CUDA acceleration:
#    (Ensure you have the CUDA Toolkit installed)
#    CMAKE_ARGS="-DLLAMA_CUBLAS=on" FORCE_CMAKE=1 pip install llama-cpp-python --upgrade --force-reinstall --no-cache-dir

# 3. Install the rest of the packages:
#    pip install -r requirements.txt


# === For CPU-Only Users ===
# 1. Install PyTorch (CPU version is standard):
#    pip install torch torchvision torchaudio

# 2. Install llama-cpp-python (will compile for CPU):
#    pip install llama-cpp-python

# 3. Install the rest of the packages:
#    pip install -r requirements.txt
